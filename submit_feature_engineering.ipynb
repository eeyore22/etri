{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_with_labels.pickle', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "\n",
    "with open('validation_with_labels.pickle', 'rb') as f:\n",
    "    val_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, exclude_columns=None):\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = ['date', 'userId', 'timestamp']\n",
    "\n",
    "\n",
    "    string_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    string_features = [col for col in string_features if col not in exclude_columns]\n",
    "\n",
    "\n",
    "    df_encoded = pd.get_dummies(df, columns=string_features)\n",
    "   \n",
    "    for col in df_encoded.select_dtypes(include=['bool']).columns:\n",
    "        df_encoded[col] = df_encoded[col].astype(int)\n",
    "\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "train_encoded = one_hot_encode(train_set)\n",
    "train_encoded.drop(columns=['userId', 'date', 'timestamp'], inplace=True)\n",
    "val_encoded = one_hot_encode(val_set)\n",
    "val_encoded.drop(columns=['subject_id', 'date', 'timestamp'], inplace=True)\n",
    "\n",
    "\n",
    "train_encoded.rename(columns={'Q1': 'daily_Q1',\n",
    "                   'Q2': 'daily_Q2',\n",
    "                   'Q3': 'daily_Q3',\n",
    "                   'S1': 'daily_S1',\n",
    "                   'S2': 'daily_S2',\n",
    "                   'S3': 'daily_S3',\n",
    "                   'S4': 'daily_S4'}, inplace=True)\n",
    "\n",
    "val_encoded.rename(columns={'Q1': 'daily_Q1',\n",
    "                   'Q2': 'daily_Q2',\n",
    "                   'Q3': 'daily_Q3',\n",
    "                   'S1': 'daily_S1',\n",
    "                   'S2': 'daily_S2',\n",
    "                   'S3': 'daily_S3',\n",
    "                   'S4': 'daily_S4'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics and features\n",
    "metrics = ['daily_Q1', 'daily_Q2', 'daily_Q3', 'daily_S1', 'daily_S2', 'daily_S3', 'daily_S4']\n",
    "features = [\n",
    " 'heart_rate',\n",
    " 'magnitude_mAcc',\n",
    " 'bvp_positive',\n",
    " 'bvp_negative',\n",
    " 'temp',\n",
    " 'magnitude_e4Acc',\n",
    " 'latitude',\n",
    " 'longitude',\n",
    " 'accuracy',\n",
    " 'magnitude_mMag',\n",
    " 'eda',\n",
    " 'magnitude_mGyr',\n",
    " 'emotionPositive',\n",
    " 'emotionTension',\n",
    " 'sleep',\n",
    " 'sleepProblem',\n",
    " 'dream',\n",
    " 'amCondition',\n",
    " 'amEmotion',\n",
    " 'pmEmotion',\n",
    " 'pmStress',\n",
    " 'pmFatigue',\n",
    " 'wakeupduration',\n",
    " 'lightsleepduration',\n",
    " 'deepsleepduration',\n",
    " 'wakeupcount',\n",
    " 'durationtosleep',\n",
    " 'remsleepduration',\n",
    " 'durationtowakeup',\n",
    " 'hr_average',\n",
    " 'rr_average',\n",
    " 'breathing_disturbances_intensity',\n",
    " 'snoring',\n",
    " 'snoringepisodecount',\n",
    " 'sleep_score',\n",
    " 'action_care_housemem',\n",
    " 'action_community_interaction',\n",
    " 'action_entertainment',\n",
    " 'action_hobby',\n",
    " 'action_household',\n",
    " 'action_meal',\n",
    " 'action_outdoor_act',\n",
    " 'action_personal_care',\n",
    " 'action_recreation_etc',\n",
    " 'action_recreation_media',\n",
    " 'action_shop',\n",
    " 'action_sleep',\n",
    " 'action_socialising',\n",
    " 'action_study',\n",
    " 'action_travel',\n",
    " 'action_work',\n",
    " 'condition_ALONE',\n",
    " 'condition_WITH_MANY',\n",
    " 'condition_WITH_ONE',\n",
    " 'place_home',\n",
    " 'place_other_indoor',\n",
    " 'place_outdoor',\n",
    " 'place_restaurant',\n",
    " 'place_workplace',\n",
    " 'activity_IN_VEHICLE',\n",
    " 'activity_ON_FOOT',\n",
    " 'activity_STILL',\n",
    " 'activity_UNKNOWN',\n",
    " 'caffeine_caffeinated drink',\n",
    " 'caffeine_coffee',\n",
    " 'caffeine_coke',\n",
    " 'caffeine_tea',\n",
    " 'caffeine_unknown',\n",
    " 'alcohol_beer',\n",
    " 'alcohol_beer&rice wine',\n",
    " 'alcohol_not specified',\n",
    " 'alcohol_soju',\n",
    " 'alcohol_soju&beer',\n",
    " 'alcohol_unknown',\n",
    " 'alcohol_wine']\n",
    "\n",
    "\n",
    "# Dictionary to store top 3 features for each metric\n",
    "top_features_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "# Loop through each metric\n",
    "for metric in metrics:\n",
    "    y = train_encoded[metric]\n",
    "    X = train_encoded[features]\n",
    "   \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "   \n",
    "    # Train the Random Forest model\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "   \n",
    "    # Compute permutation importance\n",
    "    result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "   \n",
    "    # Summarize feature importance\n",
    "    perm_importance_df = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': result.importances_mean,\n",
    "        'std': result.importances_std\n",
    "    })\n",
    "    perm_importance_df = perm_importance_df.sort_values(by='importance', ascending=False)\n",
    "   \n",
    "    # Store the top 3 features for this metric along with their importance and std\n",
    "    top_features = perm_importance_df.head(3).apply(lambda row: f\"{row['feature']} (imp: {row['importance']:.4f}, std: {row['std']:.4f})\", axis=1).values\n",
    "    top_features_dict[metric].extend(top_features)\n",
    "\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "top_features_df = pd.DataFrame(top_features_dict)\n",
    "\n",
    "\n",
    "# Identify unique features and highlight them\n",
    "all_features = [feature.split(' ')[0] for feature in top_features_df.values.flatten()]\n",
    "unique_features = set(feature for feature in all_features if all_features.count(feature) == 1)\n",
    "\n",
    "\n",
    "# Function to highlight unique features with CSS\n",
    "def highlight_unique(s):\n",
    "    feature_names = [val.split(' ')[0] for val in s]\n",
    "    return ['background-color: lightblue; color: black' if v in unique_features else 'background-color: white; color: black' for v in feature_names]\n",
    "\n",
    "\n",
    "# Apply the highlighting function to the DataFrame\n",
    "styled_top_features_df = top_features_df.style.apply(highlight_unique, axis=0)\n",
    "\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_top_features_df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
